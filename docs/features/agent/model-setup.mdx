The models you set up for Chat mode will be used with Agent mode if the model supports tool calling. The recommended models and how to set them up can be found [here](/features/chat/model-setup).

## System Message Tools

<Info>
  System message tools are experimental and may change in future releases.
</Info>

Continue implements an innovative approach called **system message tools** that ensures consistent tool functionality across all models, regardless of their native capabilities. This allows Agent mode to work seamlessly with a wider range of models and providers.

### How It Works

Instead of relying solely on native tool calling APIs (which vary between providers), Continue converts tools into XML format and includes them in the system message. The model generates tool calls as structured XML within its response, which Continue then parses and executes. This approach provides:

- **Universal compatibility** - Any model capable of following instructions can use tools, not just those with native tool support
- **Consistent behavior** - Tool calls work identically across OpenAI, Anthropic, local models, and others
- **Better reliability** - Models that struggle with native tools often perform better with system message tools
- **Seamless switching** - Change between providers without modifying your workflow

### Recommended Models

For the best Agent mode experience, we recommend models with strong reasoning and instruction-following capabilities:

**Premium Models:**
- **Claude Sonnet 4** (Anthropic) - Our top recommendation for its exceptional tool use and reasoning
- **GPT-4** models (OpenAI) - Excellent native tool support
- **DeepSeek** models - Strong performance with competitive pricing

**Local Models:**
While more limited in capabilities, these models can work with system message tools:
- Qwen2.5-Coder 32B - Best local option for Agent mode
- Devstral 27B - Good for code-specific tasks
- Smaller models (7B-13B) - May struggle with complex tool interactions

### Configuration

Agent mode automatically determines whether to use native or system message tools based on the model's capabilities. No additional configuration is required - simply select your model and Continue handles the rest.
