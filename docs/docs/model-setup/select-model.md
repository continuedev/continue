---
title: Select model
description: Swap out different LLMs
keywords: [gpt-4, codellama, claude-2, wizardcoder, wizardcoder]
---

# Select a Large Language Model

Continue makes it easy to swap out different LLMs. You can either click the "+" button next to the model dropdown to configure in the GUI or manually add them to your `config.json`. Once you've done this, you will be able to switch between them in the model selection dropdown.

**In addition to selecting a LLM, you will need to figure out [what model provider to use](./select-provider.md).**

## Open-source LLMs

The default models available in the GUI:

- [Code Llama-Instruct-7B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#1-code-llama)
- [Code Llama-Instruct-13B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#1-code-llama)
- [Code Llama-Instruct-34B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#1-code-llama)
- [Code Llama-Instruct-70B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#1-code-llama)
- [WizardCoder-7B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#2-wizardcoder)
- [WizardCoder-13B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#2-wizardcoder)
- [WizardCoder-34B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#2-wizardcoder)
- [Phind-CodeLlama-34B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#3-phind-codellama)
- [Mistral-Instruct-7B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#4-mistral)
- [StarCoder-15B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#5-starcoder)
- [Deepseek-Coder-1.3b-Instruct](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#6-deepseek-coder)
- [Deepseek-Coder-6.7b-Instruct](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#6-deepseek-coder)
- [Deepseek-Coder-33b-Instruct](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#6-deepseek-coder)
- [Llama2-Chat-7B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#7-llama2)
- [Llama2-Chat-13B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#7-llama2)
- [Llama2-Chat-70B](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#7-llama2)
- [CodeUp-13B](https://huggingface.co/deepse/CodeUp-Llama-2-13b-chat-hf)
- [Zephyr-7B](https://huggingface.co/huggingfaceh4/zephyr-7b-beta)
- [Neural-Chat-7B](https://huggingface.co/Intel/neural-chat-7b-v3-3)

**You can also use other open-source models**, you just need to manually add them to your `config.json`.

## Commercial LLMs

Models available for configuration in the GUI:

- [GPT-4](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#1-gpt-4)
- [GPT-4-Turbo](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#2-gpt-4-turbo)
- [GPT-3.5-Turbo](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#3-gpt-35-turbo)
- [Claude-2](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#4-claude-2)
- [Gemini Pro](https://github.com/continuedev/what-llm-to-use/blob/main/README.md#5-palm-2)

**You can also use other commercial models**, you just need to manually add them to your `config.json`.
