---
title: Anthropic
slug: ../anthropic
---

import TabItem from "@theme/TabItem";
import Tabs from "@theme/Tabs";

:::info
You can get an API key from the [Anthropic console](https://console.anthropic.com/account/keys).
:::

## Chat model

We recommend configuring **Claude 4 Sonnet** as your chat model.

<Tabs groupId="config-example">
  <TabItem value="yaml" label="YAML">
  ---
  </TabItem>
  <TabItem value="json" label="JSON">
  ---
  </TabItem>
</Tabs>

## Autocomplete model

Anthropic currently does not offer any autocomplete models.

[Click here](../../model-roles/autocomplete.md) to see a list of autocomplete model providers.

## Embeddings model

Anthropic currently does not offer any embeddings models.

[Click here](../../model-roles/embeddings.mdx) to see a list of embeddings model providers.

## Reranking model

Anthropic currently does not offer any reranking models.

[Click here](../../model-roles/reranking.mdx) to see a list of reranking model providers.

## Prompt caching

Anthropic supports [prompt caching with Claude](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching), which allows Claude models to cache system messages and conversation history between requests to improve performance and reduce costs.

>NOTE: As part of their `Beta` support [Extended caching](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching#1-hour-cache-duration)

### Basic Caching Options

* `cacheSystemMessage` - if `true`, caches the system message across requests
* `cacheConversation` - if `true`, enables conversation caching (required for enhanced caching)
* `useExtendedCacheTtlBeta` - if `true` will enable Beta feature and allow to set 5m or 1h ttl for caching
* `cacheTtl` - accepts only `5m` or `1h` as values, and if parameter not set `5m` default cache will be used then.

### Enhanced Caching (Per-Message-Type)

For more granular control, especially useful in **Agent mode** with tool usage, you can specify exactly how many of each message type to cache:

* `cacheUserMessages` - Number of recent user messages to cache (default: 2)
* `cacheAssistantMessages` - Number of recent assistant messages to cache (default: 0)
* `cacheToolResults` - Number of recent tool result messages to cache (default: 0)
* `cacheAssistantToolCalls` - Number of recent assistant tool call messages to cache (default: 0)

### Model Support

Prompt caching is generally available for:

- Claude 4 Sonnet
- Claude 3.7 Sonnet
- Claude 3.5 Sonnet
- Claude 3.5 Haiku

### Basic Configuration

To enable basic caching of the system message and conversation history:

<Tabs groupId="config-example">
  <TabItem value="yaml" label="YAML">
  ---
  </TabItem>
  <TabItem value="json" label="JSON">
  ---
  </TabItem>
</Tabs>

### Enhanced Configuration for Agent Mode

For heavy Agent mode usage with tool calls, use enhanced per-type caching to maximize efficiency:

<Tabs groupId="config-example">
  <TabItem value="yaml" label="YAML">
  ---
  </TabItem>
  <TabItem value="json" label="JSON">
  ---
  </TabItem>
</Tabs>

### Caching Strategy Examples

**Conservative (Cost-optimized):**
---

**Balanced (Recommended for Agent mode):**
---

**Aggressive (Maximum caching for heavy usage):**
---

### Benefits

Enhanced caching provides significant benefits for Agent mode usage:

- **Cost Reduction**: 20-30% reduction in input token costs for tool-heavy conversations
- **Performance**: Faster response times due to cached content
- **Efficiency**: Maximizes cache hits for repetitive tool operations
- **Flexibility**: Fine-tune caching per message type based on your usage patterns

The enhanced caching is particularly effective when using Continue's Agent mode with frequent tool calls, as it caches both tool results and assistant tool call messages that would otherwise consume expensive input tokens on every request.