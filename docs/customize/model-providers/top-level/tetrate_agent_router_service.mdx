---
title: "Tetrate Agent Router Service"
sidebarTitle: "Tetrate Agent Router Service"
slug: ../tetrate-agent-router-service
---

The **Tetrate Agent Router Service** provides a unified Gateway for accessing various AI models with fast inference capabilities as well as embedding services.

This gateway acts as an intelligent router that can distribute requests across multiple model providers, offering enterprise-grade reliability and performance optimization.

## Getting Started

1. Obtain an API key from the [Tetrate Agent Router Service portal](https://api.router.tetrate.ai/)
2. Configure Continue to use Tetrate Agent Router Service as your model provider

## Configuring Models

You can also quickly use models from Tetrate on the Cotninue Hub by visiting Tetrate on the Continue Hub [here](https://hub.continue.dev/tetrate). The easiest way if you don't see the model you want to use is to remix one of the models on the Tetrate page and change the model to the one you want to use.

![Tetrate on Continue Hub](../assets/tetrate-remix.png)

### Available Models

Tetrate Agent Router Service supports routing to various models.
Go to the [Tetrate Agent Router Service model catalog](https://router.tetrate.ai/models) for a full list of supported models.

## Configuration Options

Update your Continue configuration file (`~/.continue/config.yaml`) with your Tetrate Agent Router Service API key:

### On your local machine

#### In your config.yaml

```yaml title="config.yaml"
models:
  - name: <MODEL_NAME>
    provider: openai
    model: <MODEL_ID>
    apiKey: <TETRATE_API_KEY>
    apiBase: https://api.router.tetrate.ai/v1
```

#### As a model block

Review the configuration reference for [model blocks](/reference#models). Ensure you look at the roles and capabilities section and review the [model capabilities guide](/customize/deep-dives/model-capabilities).
Learn how to use model blocks on your local machine by following the [create a block](/hub/blocks/create-a-block) guide and then putting the models in a `models` directory in your local machine's `.continue` folder.

```yaml
    name: <MODEL_NAME>
    models:
      - name: <MODEL_NAME>
        provider: openai
        model: <MODEL_ID>
        apiKey: ${{ inputs.TETRATE_API_KEY }}
        apiBase: https://api.router.tetrate.ai/v1
        roles:
          - chat
          - edit
          - apply
        capabilities:
          - tool_use
```

### On Continue Hub
Learn how to use model blocks on Continue Hub [here](/hub/blocks/create-a-block).

```yaml
    name: <MODEL_NAME>
    models:
      - name: <MODEL_NAME>
        provider: openai
        model: <MODEL_ID>
        apiKey: ${{ inputs.TETRATE_API_KEY }}
        apiBase: https://api.router.tetrate.ai/v1
        roles:
          - chat
          - edit
          - apply
        capabilities:
          - tool_use
```
