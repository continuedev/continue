---
title: "How to Use Continue Guides"
description: "Comprehensive collection of practical guides for Continue including model setup, local development with Ollama, offline usage, self-hosting, custom context providers, and advanced customization tutorials"
---

## What Model & Setup Guides Are Available

- [Using Ollama with Continue](/guides/ollama-guide) - Local AI development with Ollama
- [Setting up Codestral](/guides/set-up-codestral) - Configure Mistral's Codestral model
- [How to Self-Host a Model](/guides/how-to-self-host-a-model) - Self-hosting AI models
- [Running Continue Without Internet](/guides/running-continue-without-internet) - Offline development setup
- [Llama 3.1 Setup](/guides/llama3.1) - Getting started with Llama 3.1

## Continuous AI 
- [Continuous AI: A Developer's Guide](/guides/continuous-ai) - Integrating AI into development workflows
- [How to Use Continue CLI (cn)](/guides/continue-cli) - Command-line interface for Continue

## What Advanced Tutorials Are Available

- [Build Your Own Context Provider](/guides/build-your-own-context-provider) - Create custom context providers
- [Custom Code RAG](/guides/custom-code-rag) - Implement custom retrieval-augmented generation

## How to Contribute to Guides

Have a guide idea or found an issue? We welcome contributions! Check our [GitHub repository](https://github.com/continuedev/continue) to get involved.
