{
  "title": "SerializedContinueConfig",
  "$ref": "#/definitions/continuedev__core__config__SerializedContinueConfig",
  "definitions": {
    "BaseCompletionOptions": {
      "title": "BaseCompletionOptions",
      "type": "object",
      "properties": {
        "temperature": {
          "title": "Temperature",
          "description": "The temperature of the completion.",
          "type": "number"
        },
        "top_p": {
          "title": "Top P",
          "description": "The top_p of the completion.",
          "type": "number"
        },
        "top_k": {
          "title": "Top K",
          "description": "The top_k of the completion.",
          "type": "integer"
        },
        "presence_penalty": {
          "title": "Presence Penalty",
          "description": "The presence penalty Aof the completion.",
          "type": "number"
        },
        "frequency_penalty": {
          "title": "Frequency Penalty",
          "description": "The frequency penalty of the completion.",
          "type": "number"
        },
        "stop": {
          "title": "Stop",
          "description": "The stop tokens of the completion.",
          "type": "array",
          "items": {
            "type": "string"
          }
        },
        "max_tokens": {
          "title": "Max Tokens",
          "description": "The maximum number of tokens to generate.",
          "default": 1023,
          "type": "integer"
        }
      }
    },
    "RequestOptions": {
      "title": "RequestOptions",
      "type": "object",
      "properties": {
        "timeout": {
          "title": "Timeout",
          "description": "Set the timeout for each request to the LLM. If you are running a local LLM that takes a while to respond, you might want to set this to avoid timeouts.",
          "default": 300,
          "type": "integer"
        },
        "verify_ssl": {
          "title": "Verify Ssl",
          "description": "Whether to verify SSL certificates for requests.",
          "type": "boolean"
        },
        "ca_bundle_path": {
          "title": "Ca Bundle Path",
          "description": "Path to a custom CA bundle to use when making the HTTP request",
          "type": "string"
        },
        "proxy": {
          "title": "Proxy",
          "description": "Proxy URL to use when making the HTTP request",
          "type": "string"
        },
        "headers": {
          "title": "Headers",
          "description": "Headers to use when making the HTTP request",
          "type": "object",
          "additionalProperties": {
            "type": "string"
          }
        }
      }
    },
    "ModelDescription": {
      "title": "ModelDescription",
      "type": "object",
      "properties": {
        "title": {
          "title": "Title",
          "description": "The title you wish to give your model.",
          "type": "string"
        },
        "provider": {
          "title": "Provider",
          "description": "The provider of the model. This is used to determine the type of model, and how to interact with it.",
          "enum": [
            "openai",
            "free-trial",
            "openai-aiohttp",
            "anthropic",
            "bedrock",
            "together",
            "ollama",
            "huggingface-tgi",
            "huggingface-inference-api",
            "llama.cpp",
            "replicate",
            "text-gen-webui",
            "google-palm",
            "lmstudio",
            "llamafile"
          ],
          "type": "string"
        },
        "model": {
          "title": "Model",
          "description": "The name of the model. Used to autodetect prompt template.",
          "type": "string"
        },
        "api_key": {
          "title": "Api Key",
          "description": "OpenAI, Anthropic, Together, or other API key",
          "type": "string"
        },
        "api_base": {
          "title": "Api Base",
          "description": "The base URL of the LLM API.",
          "type": "string"
        },
        "context_length": {
          "title": "Context Length",
          "description": "The maximum context length of the LLM in tokens, as counted by count_tokens.",
          "default": 2048,
          "type": "integer"
        },
        "template": {
          "title": "Template",
          "description": "The chat template used to format messages. This is auto-detected for most models, but can be overridden here.",
          "enum": [
            "llama2",
            "alpaca",
            "zephyr",
            "phind",
            "anthropic",
            "chatml",
            "deepseek",
            "neural-chat"
          ],
          "type": "string"
        },
        "completion_options": {
          "title": "Completion Options",
          "description": "Options for the completion endpoint. Read more about the completion options in the documentation.",
          "default": {
            "temperature": null,
            "top_p": null,
            "top_k": null,
            "presence_penalty": null,
            "frequency_penalty": null,
            "stop": null,
            "max_tokens": 1023
          },
          "allOf": [
            {
              "$ref": "#/definitions/BaseCompletionOptions"
            }
          ]
        },
        "system_message": {
          "title": "System Message",
          "description": "A system message that will always be followed by the LLM",
          "type": "string"
        },
        "request_options": {
          "title": "Request Options",
          "description": "Options for the HTTP request to the LLM.",
          "default": {
            "timeout": 300,
            "verify_ssl": null,
            "ca_bundle_path": null,
            "proxy": null,
            "headers": null
          },
          "allOf": [
            {
              "$ref": "#/definitions/RequestOptions"
            }
          ]
        }
      },
      "required": ["title", "provider", "model"]
    },
    "ModelRoles": {
      "title": "ModelRoles",
      "type": "object",
      "properties": {
        "default": {
          "title": "Default",
          "description": "The default model. If other model roles are not set, they will fall back to default.",
          "type": "string"
        },
        "chat": {
          "title": "Chat",
          "description": "The model to use for chat. If not set, will fall back to default.",
          "type": "string"
        },
        "edit": {
          "title": "Edit",
          "description": "The model to use for editing. If not set, will fall back to default.",
          "type": "string"
        },
        "summarize": {
          "title": "Summarize",
          "description": "The model to use for summarization. If not set, will fall back to default.",
          "type": "string"
        }
      },
      "required": ["default"]
    },
    "SlashCommand": {
      "title": "SlashCommand",
      "type": "object",
      "properties": {
        "name": {
          "title": "Name",
          "type": "string"
        },
        "description": {
          "title": "Description",
          "type": "string"
        },
        "step": {
          "title": "Step",
          "anyOf": [
            {},
            {
              "enum": [
                "AnswerQuestionChroma",
                "GenerateShellCommandStep",
                "EditHighlightedCodeStep",
                "ShareSessionStep",
                "CommentCodeStep",
                "ClearHistoryStep",
                "StackOverflowStep",
                "OpenConfigStep"
              ],
              "type": "string"
            },
            {
              "type": "string"
            }
          ]
        },
        "params": {
          "title": "Params",
          "default": {},
          "type": "object"
        }
      },
      "required": ["name", "description", "step"]
    },
    "CustomCommand": {
      "title": "CustomCommand",
      "type": "object",
      "properties": {
        "name": {
          "title": "Name",
          "type": "string"
        },
        "prompt": {
          "title": "Prompt",
          "type": "string"
        },
        "description": {
          "title": "Description",
          "type": "string"
        }
      },
      "required": ["name", "prompt", "description"]
    },
    "ContextProviderWithParams": {
      "title": "ContextProviderWithParams",
      "type": "object",
      "properties": {
        "name": {
          "title": "Name",
          "enum": [
            "diff",
            "github",
            "terminal",
            "open",
            "google",
            "search",
            "url",
            "tree"
          ],
          "type": "string"
        },
        "params": {
          "title": "Params",
          "default": {},
          "type": "object"
        }
      },
      "required": ["name"]
    },
    "RetrievalSettings": {
      "title": "RetrievalSettings",
      "type": "object",
      "properties": {
        "n_retrieve": {
          "title": "N Retrieve",
          "description": "Number of results to initially retrieve from vector database",
          "default": 50,
          "type": "integer"
        },
        "n_final": {
          "title": "N Final",
          "description": "Final number of results to use after re-ranking",
          "default": 10,
          "type": "integer"
        },
        "use_reranking": {
          "title": "Use Reranking",
          "description": "Whether to use re-ranking, which will allow initial selection of n_retrieve results, then will use an LLM to select the top n_final results",
          "default": true,
          "type": "boolean"
        },
        "rerank_group_size": {
          "title": "Rerank Group Size",
          "description": "Number of results to group together when re-ranking. Each group will be processed in parallel.",
          "default": 5,
          "type": "integer"
        },
        "ignore_files": {
          "title": "Ignore Files",
          "description": "Files to ignore when indexing the codebase. You can use glob patterns, such as **/*.py. This is useful for directories that contain generated code, or other directories that are not relevant to the codebase.",
          "default": [],
          "type": "array",
          "items": {
            "type": "string"
          }
        },
        "openai_api_key": {
          "title": "Openai Api Key",
          "description": "OpenAI API key",
          "type": "string"
        },
        "api_base": {
          "title": "Api Base",
          "description": "OpenAI API base URL",
          "type": "string"
        },
        "api_type": {
          "title": "Api Type",
          "description": "OpenAI API type",
          "type": "string"
        },
        "api_version": {
          "title": "Api Version",
          "description": "OpenAI API version",
          "type": "string"
        },
        "organization_id": {
          "title": "Organization Id",
          "description": "OpenAI organization ID",
          "type": "string"
        }
      }
    },
    "continuedev__core__config__SerializedContinueConfig": {
      "title": "SerializedContinueConfig",
      "type": "object",
      "properties": {
        "disallowed_steps": {
          "title": "Disallowed Steps",
          "description": "Steps that are not allowed to be run, and will be skipped if attempted",
          "default": [],
          "type": "array",
          "items": {
            "type": "string"
          }
        },
        "allow_anonymous_telemetry": {
          "title": "Allow Anonymous Telemetry",
          "description": "If this field is set to True, we will collect anonymous telemetry as described in the documentation page on telemetry. If set to False, we will not collect any data.",
          "default": true,
          "type": "boolean"
        },
        "models": {
          "title": "Models",
          "default": [
            {
              "title": "GPT-4 (trial)",
              "provider": "free-trial",
              "model": "gpt-4",
              "api_key": "",
              "api_base": null,
              "context_length": 2048,
              "template": null,
              "completion_options": {
                "temperature": null,
                "top_p": null,
                "top_k": null,
                "presence_penalty": null,
                "frequency_penalty": null,
                "stop": null,
                "max_tokens": 1023
              },
              "system_message": null,
              "request_options": {
                "timeout": 300,
                "verify_ssl": null,
                "ca_bundle_path": null,
                "proxy": null,
                "headers": null
              }
            }
          ],
          "type": "array",
          "items": {
            "$ref": "#/definitions/ModelDescription"
          }
        },
        "model_roles": {
          "title": "Model Roles",
          "description": "Roles for models. Each entry should be the title of a model in the models array.",
          "default": {
            "default": "GPT-4 (trial)",
            "chat": null,
            "edit": null,
            "summarize": null
          },
          "allOf": [
            {
              "$ref": "#/definitions/ModelRoles"
            }
          ]
        },
        "system_message": {
          "title": "System Message",
          "description": "A system message that will always be followed by the LLM",
          "type": "string"
        },
        "completion_options": {
          "title": "Completion Options",
          "description": "Default options for completion. These will be overriden by any options set for a specific model.",
          "default": {
            "temperature": null,
            "top_p": null,
            "top_k": null,
            "presence_penalty": null,
            "frequency_penalty": null,
            "stop": null,
            "max_tokens": 1023
          },
          "allOf": [
            {
              "$ref": "#/definitions/BaseCompletionOptions"
            }
          ]
        },
        "slash_commands": {
          "title": "Slash Commands",
          "description": "An array of slash commands that let you map custom Steps to a shortcut.",
          "default": [],
          "type": "array",
          "items": {
            "$ref": "#/definitions/SlashCommand"
          }
        },
        "custom_commands": {
          "title": "Custom Commands",
          "description": "An array of custom commands that allow you to reuse prompts. Each has name, description, and prompt properties. When you enter /<name> in the text input, it will act as a shortcut to the prompt.",
          "default": [
            {
              "name": "test",
              "prompt": "Write a comprehensive set of unit tests for the selected code. It should setup, run tests that check for correctness including important edge cases, and teardown. Ensure that the tests are complete and sophisticated. Give the tests just as chat output, don't edit any file.",
              "description": "This is an example custom command. Use /config to edit it and create more"
            }
          ],
          "type": "array",
          "items": {
            "$ref": "#/definitions/CustomCommand"
          }
        },
        "context_providers": {
          "title": "Context Providers",
          "description": "A list of ContextProvider objects that can be used to provide context to the LLM by typing '@'. Read more about ContextProviders in the documentation.",
          "default": [],
          "type": "array",
          "items": {
            "$ref": "#/definitions/ContextProviderWithParams"
          }
        },
        "user_token": {
          "title": "User Token",
          "description": "An optional token to identify the user.",
          "type": "string"
        },
        "data_server_url": {
          "title": "Data Server Url",
          "description": "The URL of the server where development data is sent. No data is sent unless you have explicitly set the `user_token` property to a valid token that we have shared.",
          "default": "https://us-west1-autodebug.cloudfunctions.net",
          "type": "string"
        },
        "disable_summaries": {
          "title": "Disable Summaries",
          "description": "If set to `True`, Continue will not generate summaries for each Step. This can be useful if you want to save on compute.",
          "default": false,
          "type": "boolean"
        },
        "disable_indexing": {
          "title": "Disable Indexing",
          "description": "If set to `True`, Continue will not index the codebase. This is mainly used for debugging purposes.",
          "default": false,
          "type": "boolean"
        },
        "retrieval_settings": {
          "title": "Retrieval Settings",
          "description": "Settings for the retrieval system. Read more about the retrieval system in the documentation.",
          "default": {
            "n_retrieve": 50,
            "n_final": 10,
            "use_reranking": true,
            "rerank_group_size": 5,
            "ignore_files": [],
            "openai_api_key": null,
            "api_base": null,
            "api_type": null,
            "api_version": null,
            "organization_id": null
          },
          "allOf": [
            {
              "$ref": "#/definitions/RetrievalSettings"
            }
          ]
        }
      }
    }
  }
}
